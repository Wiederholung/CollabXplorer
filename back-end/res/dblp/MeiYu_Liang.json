{"id": "150/1513", "name": "MeiYu Liang", "Article": {"conf/bigcomp/ChenLYHW21": {"title": "Intelligent Teaching Evaluation System Integrating Facial Expression and Behavior Recognition in Teaching Video.", "url": "https://doi.org/10.1109/BigComp51126.2021.00019", "year": "2021", "author": {"Zheng Chen": "33/2592", "MeiYu Liang": "150/1513", "Wanying Yu": "288/3257", "Yongkang Huang": "288/2943", "Xiaoxiao Wang 0006": "01/447-6"}, "abstract": " Abstract:The student's listening status in the classroom is an important indicator to evaluate that if he takes an active participation in the classroom and study seriously. However, the main challenge in the teaching evaluation is that the teacher in class cannot timely, objectively and accurately evaluate each student's state of listening in accordance with the facial expression or behavior of the students. Along with the advance of deep learning algorithms, artificial intelligence technology is more and more widely applied in the field of education. Based on the above challenges, this paper proposes an intelligent teaching evaluation method that integrates student facial expressions and behaviors in teaching videos, designs and implements a deep learning based intelligent teaching evaluation system. We construct the face detection and recognition model based on deep convolutional neural network and triple loss function to realize the detection and recognition of face regions of students. And then the student facial expression recognition model and the student behavior recognition model based on the deep separable convolutional neural network are constructed. Finally, we propose a novel comprehensive teaching evaluation algorithm by fusion of the student facial expression and behavior, aiming at calculating the comprehensive evaluation value and obtain the corresponding evaluation level. Also, we construct the first teaching video database, student facial expression database and student behavior database for intelligent teaching evaluation. In this paper, the evaluation of students fully combines the students' specific facial expressions under certain behaviors in the classroom. Therefore, the final teaching assessment results are more comprehensive and accurate."}, "conf/bigcomp/WangLCD21": {"title": "Dual-pathway Attention based Supervised Adversarial Hashing for Cross-modal Retrieval.", "url": "https://doi.org/10.1109/BigComp51126.2021.00040", "year": "2021", "author": {"Xiaoxiao Wang 0006": "01/447-6", "MeiYu Liang": "150/1513", "Xiaowen Cao": "154/5940", "Junping Du": "13/1151"}, "abstract": " Abstract:Due to the success of deep learning in recent years, cross-modal retrieval has made significant progress. However, there is still a key challenge: how to learn the correlation between different modality data more effectively to improve the retrieval accuracy. Therefore, in this paper we proposed a Dual-pathway Attention based Supervise Adversarial Hashing (DASAH) to obtain a unified cross-modal semantic representation. Based on Dual-pathway attention, that is, learning the attention of image regions (text sequences) to text sequences (image regions), the fine-grained semantic correlation between different modality data is deeply mined, and the adversarial learning is integrated to further improve the learning ability of cross-modal semantic correlation. The model makes full use of dual-pathway attention to guide fine-grained cross modal feature learning, and integrates fine-grained cross modal feature learning and adversarial hashing learning in a unified framework for joint learning and optimization. Extensive empirical studies show that the proposed method outperforms several state-of-the-art methods for cross-modal retrieval."}, "conf/ccis/OuyangDWYWL21": {"title": "Federal Learning Based COVID-19 Fake News Detection With Deep Self-Attention Network.", "url": "https://doi.org/10.1109/CCIS53392.2021.9754663", "year": "2021", "author": {"Suyu Ouyang": "317/5495", "Junping Du": "13/1151", "Benzhi Wang": "316/4704", "Bowen Yu": "95/10266", "Yuhui Wang": "52/3971", "MeiYu Liang": "150/1513"}, "abstract": " Abstract:As social media becomes more and more popular, fake news spreads rapidly which is more likely to cause serious consequences, especially during the COVID-19 pandemic. On the premise of meeting data privacy and security requirements, federated learning uses multi-party heterogeneous data to further promote machine learning. This paper proposes a federal learning based COVID-19 fake news detection model with deep self-attention network (FL_FNDM). We construct a deep self-attention network for fake news detection, which combines self-attention-based pretrained model BERT and deep convolutional neural network to detect fake news. Moreover, the fake news detection model is learned under the framework of horizontal federated learning, aiming at protecting users’ data security and privacy. The experimental results demonstrate that the proposed model can improve the performance of fake news detection on the COVID-19 dataset, which can achieve almost the same effect of sharing data without leaking user data."}, "conf/cicai/SongXDKLX21": {"title": "Multi-view Relevance Matching Model of Scientific Papers Based on Graph Convolutional Network and Attention Mechanism.", "url": "https://doi.org/10.1007/978-3-030-93046-2_61", "year": "2021", "author": {"Jie Song": "09/4756", "Zhe Xue": "116/7294", "Junping Du": "13/1151", "Feifei Kou": "223/2313", "MeiYu Liang": "150/1513", "Mingying Xu": "289/1484"}, "abstract": "Deep learning has been widely used in text matching tasks. However, the existing deep learning models are mainly designed for short texts matching and cannot be directly applied to the search of scientific papers. The main reason is that the differences between long and short texts in scientific paper search have not been fully considered, and the structural information of the text will be lost when the length difference is large. In order to solve the above long-short scientific text matching problem, we propose a multi-view relevance matching model (MVRM) of scientific papers based on graph convolutional network and attention mechanism. First, we use scientific papers abstract to construct interactive graph to retain the structural information in the long text. Each vertex denotes the keyword in the abstract and the edge weight denotes similarity between the keywords. Second, we propose a matching network for interactive graph based on the graph convolution networks. Multiple keywords in the search term form multiple views, and each keyword under each view interacts with the interactive graph. Then the interaction feature vectors from multiple views are generated through graph convolution network. Finally, attention mechanism is used for fusion, and the final matching result is output through the multilayer perceptron. Experiments on several representative scientific paper search datasets demonstrate that our model achieves better performance.KeywordsRelevance matchingGraph convolutional networkAttention mechanismMulti-viewLong-short text matching"}, "conf/cicai/ZhengXDKLX21": {"title": "A Hierarchical Multi-label Classification Algorithm for Scientific Papers Based on Graph Attention Networks.", "url": "https://doi.org/10.1007/978-3-030-93046-2_62", "year": "2021", "author": {"Changwei Zheng": "11/10184", "Zhe Xue": "116/7294", "Junping Du": "13/1151", "Feifei Kou": "223/2313", "MeiYu Liang": "150/1513", "Mingying Xu": "289/1484"}, "abstract": "Scientific paper classification refers to assigning one or more subject categories to papers. This task requires a lot of domain knowledge and heavy manual annotation. With the gradual increase in interdisciplinary research, a paper often has multiple categories. For instance, both Chinese Library Classification (http://www.ztflh.com/) and Engineering Village (EI) have a complete classification system, and there is a hierarchical relationship between the categories. The category of the paper has a hierarchical structure, so the paper classification can be converted into a hierarchical classification problem. However, the existing methods cannot effectively classify papers due to the following two reasons: First, these methods cannot well capture the semantic relationship between papers. Second, they neglect to model the hierarchical structure of labels. In this paper, we propose a hierarchical label attention model based on graph attention network, which utilizes word co-occurrence to model the semantic relationship of papers. We use multiple linear layers to model the category hierarchy and combine every hierarchy of labels through an attention mechanism. The experiments are conducted on CNKI (https://www.cnki.net/) and RCV1 datasets. The experimental results demonstrate that our method is superior to the other methods in the task of scientific paper classification.KeywordsGraph convolutional networkHierarchical classificationMulti-label classification"}, "conf/ijcai/XueDZSRL21": {"title": "Clustering-Induced Adaptive Structure Enhancing Network for Incomplete Multi-View Data.", "url": "https://doi.org/10.24963/ijcai.2021/445", "year": "2021", "author": {"Zhe Xue": "116/7294", "Junping Du": "13/1151", "Changwei Zheng": "11/10184", "Jie Song": "09/4756", "Wenqi Ren": "126/3420", "MeiYu Liang": "150/1513"}, "abstract": ""}, "conf/mm/LiangDLXGY19": {"title": "Fine-grained Cross-media Representation Learning with Deep Quantization Attention Network.", "url": "https://doi.org/10.1145/3343031.3350892", "year": "2019", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Wu Liu": "31/4112", "Zhe Xue": "116/7294", "Yue Geng": "23/5510", "Cong-Xian Yang": "223/2400"}, "abstract": "\n\t\tCross-media search is useful for getting more comprehensive and richer information about social network hot topics or events. To solve the problems of feature heterogeneity and semantic gap of different media data, existing deep cross-media quantization technology provides an efficient and effective solution for cross-media common semantic representation learning. However, due to the fact that social network data often exhibits semantic sparsity, diversity, and contains a lot of noise, the performance of existing cross-media search methods often degrades. To address the above issue, this paper proposes a novel fine-grained cross-media representation learning model with deep quantization attention network for social network cross-media search (CMSL). First, we construct the image-word semantic correlation graph, and perform deep random walks on the graph to realize semantic expansion and semantic embedding learning, which can discover some potential semantic correlations between images and words. Then, in order to discover more fine-grained cross-media semantic correlations, a multi-scale fine-grained cross-media semantic correlation learning method that combines global and local saliency semantic similarity is proposed. Third, the fine-grained cross-media representation, cross-media semantic correlations and binary quantization code are jointly learned by a unified deep quantization attention network, which can preserve both inter-media correlations and intra-media similarities, by minimizing both cross-media correlation loss and binary quantization loss. Experimental results demonstrate that CMSL can generate high-quality cross-media common semantic representation, which yields state-of-the-art cross-media search performance on two benchmark datasets, NUS-WIDE and MIR-Flickr 25k.\n\t"}, "conf/ccis/LiDLLM16": {"title": "Video super-resolution based on nonlinear mapping and patch similarity.", "url": "https://doi.org/10.1109/CCIS.2016.7790223", "year": "2016", "author": {"Linghui Li": "19/10136", "Junping Du": "13/1151", "MeiYu Liang": "150/1513", "Jangmyung Lee": "130/8653", "Luoming Meng": "52/382"}, "abstract": " Abstract:Aiming at recovering lost detailed information in low-resolution videos, a novel video super-resolution algorithm based on nonlinear mapping and patch similarity was proposed in this paper. Taking advantage of the strong fitting ability of the convolutional neural network for the nonlinear relationship, this algorithm utilizes the learned reconstruction parameters to pad missing structures and make the low-resolution video approach to the ground truth. However, it is unavoidable to introduce irrelevant information and amplify noises in this process. The patch similarity is imported to improve the spatial-temporal consistency and anti-noise ability of this algorithm. Moreover, instead of considering the nonlocal self-similarity only, this algorithm combines the nonlocal external sparsity and spatial-temporal similarity to enrich the prior information. All these patch similarities are used to optimize the intermediate video achieved from the mapping process. Experimental results demonstrated that the proposed algorithm achieves a competitive super-resolution quality on both the subjective and the objective evaluations, when compared to other state-of-the-art algorithms."}, "conf/ccis/CaoDL14": {"title": "High dynamic range motion image sequences reconstruction.", "url": "https://doi.org/10.1109/CCIS.2014.7175814", "year": "2014", "author": {"Shouxin Cao": "08/10150", "Junping Du": "13/1151", "MeiYu Liang": "150/1513"}, "abstract": " Abstract:In this paper, we proposed a fast and efficient high dynamic range reconstruction model based on brightness compensation and multi-source bidirectional similarity (MBDS). By introducing the exposure value detecting function, the dynamic image sequence with different exposure values is divided into the high-exposure images, the low-exposure images and the reasonable exposure images. Considering that the brightness dynamic range is an important factor which greatly influences the image visual effect and its rich information contents, we improve the image brightness by the brightness enhancement algorithm for the low-exposure images. By combining the exposure value detecting and the brightness enhancement, it could improve the time efficiency and the block matching accuracy for the high dynamic range reconstruction algorithm based on MBDS, and also the artifacts and shake phenomenon produced in the reconstruction process could be reduced. Experimental results demonstrate that the proposed model could achieve better exposure compensation, which obtains more reasonable image brightness and much richer image details information."}, "conf/isie/LiangDLXLL13": {"title": "Spatio-temporal super-resolution reconstruction based on robust optical flow and Zernike moment for dynamic image sequences.", "url": "https://doi.org/10.1109/ISIE.2013.6563661", "year": "2013", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Xiaoyong Li 0003": "46/5404-3", "Liang Xu": "54/3420", "Honggang Liu": "26/2948", "Yawen Li": "30/4774"}, "abstract": " Abstract:A novel and efficient spatio-temporal super-resolution reconstruction model based on robust optical flow and Zernike moment is proposed in this paper. The model does not rely on accurate estimation of subpixel motion, and is robust to noise and rotation. Moreover, it can effectively overcome the problems of block and hole artifacts in the traditional reconstruction methods. In our super-resolution process, first we propose an efficient robust optical flow motion estimation model based on the motion details protection, then introduce the bi-weighted fusion strategy to implement the spatio-temporal motion compensation, and finally apply the multi-frame information fusion scheme to make the spatio-temporal super-resolution reconstruction and optimization based on Zernike moment and non-local self-similarity. Experimental results demonstrate that the proposed method outperforms the existing methods in terms of both subjective visual and objective quantitative evaluations."}, "conf/ccis/YangDL11": {"title": "Study on food safety semantic retrieval system based on domain ontology.", "url": "https://doi.org/10.1109/CCIS.2011.6045028", "year": "2011", "author": {"Yuehua Yang": "193/2603", "Junping Du": "13/1151", "MeiYu Liang": "150/1513"}, "abstract": " Abstract:From aspects of domain ontology construction, concept similarity computation based on ontology and semantic query expansion study the related technologies of information retrieval system based on ontology; establish food safety domain ontology and ontology-based concept similarity computation model, put forward a new semantic query expansion method based on concept similarity computation; design and implement food safety semantic retrieval system. The experiments show that this food safety semantic retrieval system is superior to the retrieval system based on keywords both in the recall ratio and the precision, and realize certain intelligent retrieval."}, "journals/tkde/LiangDLXWKW22": {"title": "Video Super-Resolution Reconstruction Based on Deep Learning and Spatio-Temporal Feature Self-Similarity.", "url": "https://doi.org/10.1109/TKDE.2020.3034261", "year": "2022", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Linghui Li": "19/10136", "Zhe Xue": "116/7294", "Xiaoxiao Wang 0006": "01/447-6", "Feifei Kou": "223/2313", "Xu Wang": "181/2815"}, "abstract": " Abstract:To address the problems in the existing video super-resolution methods, such as noise, over smooth and visual artifacts, which are caused by the reliance on limited external training or mismatch of internal similarity patch instances, this study proposes a novel video super-resolution reconstruction algorithm based on deep learning and spatio-temporal feature similarity (DLSS-VSR). The video super-resolution reconstruction mechanism with the joint internal and external constraints is established utilizing the complementary advantages of both external deep correlation mapping learning and internal spatio-temporal nonlocal self-similarity prior constraint. A deep learning model based on deep convolutional neural network is constructed to learn the nonlinear correlation mapping between low-resolution and high-resolution video frame patches. A novel spatio-temporal feature similarity calculation method is proposed, which considers both internal video spatio-temporal self-similarity and external clean nonlocal similarity. For the internal spatio-temporal feature self-similarity, we improve the accuracy and robustness of similarity matching by proposing a similarity measure strategy based on spatio-temporal moment feature similarity and structural similarity. The external nonlocal similarity prior constraint is learned by the patch group-based Gaussian mixture model. The time efficiency for spatio-temporal similarity matching is further improved based on saliency detection and region correlation judgment strategy, which achieves a better tradeoff between super-resolution accuracy and speed. Experimental results demonstrate that the DLSS-VSR algorithm achieves competitive super-resolution quality compared to other state-of-the-art algorithms in both subjective and objective evaluations."}, "journals/corr/abs-2203-15595": {"title": "Cross-Media Scientific Research Achievements Retrieval Based on Deep Language Model.", "url": "https://doi.org/10.48550/arXiv.2203.15595", "year": "2022", "author": {"Benzhi Wang": "316/4704", "MeiYu Liang": "150/1513", "Feifei Kou": "223/2313", "Mingying Xu": "289/1484"}, "abstract": "\n      Abstract:  Science and technology big data contain a lot of cross-media\ninformation.There are images and texts in the scientific paper.The s ingle\nmodal search method cannot well meet the needs of scientific researchers.This\npaper proposes a cross-media scientific research achievements retrieval method\nbased on deep language model (CARDL).It achieves a unified cross-media semantic\nrepresentation by learning the semantic association between different modal\ndata, and is applied to the generation of text semantic vector of scientific\nresearch achievements, and then cross-media retrieval is realized through\nsemantic similarity matching between different modal data.Experimental results\nshow that the proposed CARDL method achieves better cross-modal retrieval\nperformance than existing methods. Key words science and technology big data ;\ncross-media retrieval; cross-media semantic association learning; deep language\nmodel; semantic similarity\n\n    "}, "journals/corr/abs-2203-16256": {"title": "Research topic trend prediction of scientific papers based on spatial enhancement and dynamic graph convolution network.", "url": "https://doi.org/10.48550/arXiv.2203.16256", "year": "2022", "author": {"Changwei Zheng": "11/10184", "Zhe Xue": "116/7294", "MeiYu Liang": "150/1513", "Feifei Kou": "223/2313"}, "abstract": "\n      Abstract:  In recent years, with the increase of social investment in scientific\nresearch, the number of research results in various fields has increased\nsignificantly. Accurately and effectively predicting the trends of future\nresearch topics can help researchers discover future research hotspots.\nHowever, due to the increasingly close correlation between various research\nthemes, there is a certain dependency relationship between a large number of\nresearch themes. Viewing a single research theme in isolation and using\ntraditional sequence problem processing methods cannot effectively explore the\nspatial dependencies between these research themes. To simultaneously capture\nthe spatial dependencies and temporal changes between research topics, we\npropose a deep neural network-based research topic hotness prediction\nalgorithm, a spatiotemporal convolutional network model. Our model combines a\ngraph convolutional neural network (GCN) and Temporal Convolutional Network\n(TCN), specifically, GCNs are used to learn the spatial dependencies of\nresearch topics a and use space dependence to strengthen spatial\ncharacteristics. TCN is used to learn the dynamics of research topics' trends.\nOptimization is based on the calculation of weighted losses based on time\ndistance. Compared with the current mainstream sequence prediction models and\nsimilar spatiotemporal models on the paper datasets, experiments show that, in\nresearch topic prediction tasks, our model can effectively capture\nspatiotemporal relationships and the predictions outperform state-of-art\nbaselines.\n\n    "}, "journals/corr/abs-2203-16751": {"title": "An unsupervised cluster-level based method for learning node representations of heterogeneous graphs in scientific papers.", "url": "https://doi.org/10.48550/arXiv.2203.16751", "year": "2022", "author": {"Jie Song": "09/4756", "MeiYu Liang": "150/1513", "Zhe Xue": "116/7294", "Junping Du": "13/1151", "Feifei Kou": "223/2313"}, "abstract": "\n      Abstract:  Learning knowledge representation of scientific paper data is a problem to be\nsolved, and how to learn the representation of paper nodes in scientific paper\nheterogeneous network is the core to solve this problem. This paper proposes an\nunsupervised cluster-level scientific paper heterogeneous graph node\nrepresentation learning method (UCHL), aiming at obtaining the representation\nof nodes (authors, institutions, papers, etc.) in the heterogeneous graph of\nscientific papers. Based on the heterogeneous graph representation, this paper\nperforms link prediction on the entire heterogeneous graph and obtains the\nrelationship between the edges of the nodes, that is, the relationship between\npapers and papers. Experiments results show that the proposed method achieves\nexcellent performance on multiple evaluation metrics on real scientific paper\ndatasets.\n\n    "}, "journals/corr/abs-2204-05807": {"title": "Research on accurate stereo portrait generation algorithm of scientific research team.", "url": "https://doi.org/10.48550/arXiv.2204.05807", "year": "2022", "author": {"Mingying Xu": "289/1484", "MeiYu Liang": "150/1513", "Zhe Xue": "116/7294", "Ang Li": "33/2805"}, "abstract": "\n      Abstract:  In order to smoothly promote the establishment of scientific research\nprojects, accurately identify the excellent scientific research team, and\nintuitively and comprehensively describe the scientific research team, it is of\ngreat significance for the scientific research management department to\ncomprehensively understand and objectively evaluate the scientific research\nteam. At present, the research work on the construction of accurate\nthree-dimensional portrait of scientific research team is relatively less. In\nview of the practical demand of scientific research management department, this\npaper proposes an accurate stereo portrait generation algorithm of scientific\nresearch team. The algorithm includes three modules: research team\nidentification, research topic extraction and research team portrait\ngeneration. Firstly, the leader of the scientific research team is identified\nbased on the iterative middle centrality ranking method, and the members of the\nscientific research team are identified through the 2-faction and snowball\nmethods, so as to realize the identification of the scientific research team.\nThen, considering the statistical information of words and the co-occurrence\nfeatures of words in the research team, the research topics of the research\nteam are extracted to improve the accuracy of research topic extraction.\nFinally, the research team portrait generation module generates the accurate\nthree-dimensional portrait of the research team through the generation of the\nresearch team profile, the construction of the research cooperation\nrelationship, and the construction of the research team topic cloud. The\nresearch team is identified on the data set of scientific research\nachievements, and the accurate three-dimensional portraits of the research team\nare generated and visualized. Experiments verify the effectiveness of the\nproposed algorithm.\n\n    "}, "journals/corr/abs-2204-08476": {"title": "Research on Domain Information Mining and Theme Evolution of Scientific Papers.", "url": "https://doi.org/10.48550/arXiv.2204.08476", "year": "2022", "author": {"Changwei Zheng": "11/10184", "Zhe Xue": "116/7294", "MeiYu Liang": "150/1513", "Feifei Kou": "223/2313", "Zeli Guan": "241/3177"}, "abstract": "\n      Abstract:  In recent years, with the increase of social investment in scientific\nresearch, the number of research results in various fields has increased\nsignificantly. Cross-disciplinary research results have gradually become an\nemerging frontier research direction. There is a certain dependence between a\nlarge number of research results. It is difficult to effectively analyze\ntoday's scientific research results when looking at a single research field in\nisolation. How to effectively use the huge number of scientific papers to help\nresearchers becomes a challenge. This paper introduces the research status at\nhome and abroad in terms of domain information mining and topic evolution law\nof scientific and technological papers from three aspects: the semantic feature\nrepresentation learning of scientific and technological papers, the field\ninformation mining of scientific and technological papers, and the mining and\nprediction of research topic evolution rules of scientific and technological\npapers.\n\n    "}, "journals/corr/abs-2204-11488": {"title": "Mining and searching association relation of scientific papers based on deep learning.", "url": "https://doi.org/10.48550/arXiv.2204.11488", "year": "2022", "author": {"Jie Song": "09/4756", "MeiYu Liang": "150/1513", "Zhe Xue": "116/7294", "Feifei Kou": "223/2313", "Ang Li": "33/2805"}, "abstract": "\n      Abstract:  There is a complex correlation among the data of scientific papers. The\nphenomenon reveals the data characteristics, laws, and correlations contained\nin the data of scientific and technological papers in specific fields, which\ncan realize the analysis of scientific and technological big data and help to\ndesign applications to serve scientific researchers. Therefore, the research on\nmining and searching the association relationship of scientific papers based on\ndeep learning has far-reaching practical significance.\n\n    "}, "journals/corr/abs-2204-12121": {"title": "Cross-media Scientific Research Achievements Query based on Ranking Learning.", "url": "https://doi.org/10.48550/arXiv.2204.12121", "year": "2022", "author": {"Benzhi Wang": "316/4704", "MeiYu Liang": "150/1513", "Ang Li": "33/2805"}, "abstract": "\n      Abstract:  With the advent of the information age, the scale of data on the Internet is\ngetting larger and larger, and it is full of text, images, videos, and other\ninformation. Different from social media data and news data, scientific\nresearch achievements information has the characteristics of many proper nouns\nand strong ambiguity. The traditional single-mode query method based on\nkeywords can no longer meet the needs of scientific researchers and managers of\nthe Ministry of Science and Technology. Scientific research project information\nand scientific research scholar information contain a large amount of valuable\nscientific research achievement information. Evaluating the output capability\nof scientific research projects and scientific research teams can effectively\nassist managers in decision-making. In view of the above background, this paper\nexpounds on the research status from four aspects: characteristic learning of\nscientific research results, cross-media research results query, ranking\nlearning of scientific research results, and cross-media scientific research\nachievement query system.\n\n    "}, "journals/ijon/ZhouDXLYC20": {"title": "Security topics related microblogs search based on deep convolutional neural networks.", "url": "https://doi.org/10.1016/j.neucom.2018.09.105", "year": "2020", "author": {"Nan Zhou": "06/5140", "Junping Du": "13/1151", "Zhe Xue": "116/7294", "MeiYu Liang": "150/1513", "Xu Yao": "118/3673", "Wanqiu Cui": "223/2328"}, "abstract": "Social network information search, especially for microblog search, has been one of the research hotspots in the domain of information search. For complexities of microblog data on arbitrary typing and semantic ambiguity, classical approaches cannot be directly adopted. In this paper, we propose a security topics related microblogs search model based on deep convolutional neural networks (DCNN-CSTRS) to search microblogs similar to a specific security topic contents. This method is trained to capture local semantic features of short microblog texts to filter security topics related contents from microblogs. A matching model based on deep convolution neural network is designed to rank the results by matching the extracted local features of queries and documents respectively through non-linear feature transformations of the convolution and pooling. The matching model ranks the pairs of query-document by similarities. Experimental results demonstrate that the proposed approach performs better compared with the state-of-the-art methods."}, "journals/ijon/WeiDXLGXL20": {"title": "A very deep two-stream network for crowd type recognition.", "url": "https://doi.org/10.1016/j.neucom.2018.10.106", "year": "2020", "author": {"Xinlei Wei": "195/7472", "Junping Du": "13/1151", "Zhe Xue": "116/7294", "MeiYu Liang": "150/1513", "Yue Geng": "23/5510", "Xin Xu": "66/3874", "JangMyung Lee": "130/8653"}, "abstract": "Crowd type identification is a crucial task in the emergency alert. In this paper, to solve accurate identification of crowd type, the crowd type description triad C-BMO < Behavior, Mood, Organized >  and a novel crowd type recognition network (CTRN): very deep two-stream network architecture are proposed, respectively. The very deep two-stream network architecture is based on the static map and motion map in the video. To early warn the emergency, the reasoning rules of the emergency alert are proposed based on joining the crowd type and the crowd characteristics. To verify the proposed method, the crowd type dataset is collected, and we experiment with the proposed plan on the crowd type dataset. The experimental results demonstrate that the proposed model is competitive compared with the state-of-the-art techniques."}, "journals/tnn/LiangDYXLKG20": {"title": "Cross-Media Semantic Correlation Learning Based on Deep Hash Network and Semantic Expansion for Social Network Cross-Media Search.", "url": "https://doi.org/10.1109/TNNLS.2019.2945567", "year": "2020", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Cong-Xian Yang": "223/2400", "Zhe Xue": "116/7294", "Hai-Sheng Li 0002": "145/2836-2", "Feifei Kou": "223/2313", "Yue Geng": "23/5510"}, "abstract": " Abstract:Cross-media search from large-scale social network big data has become increasingly valuable in our daily life because it can support querying different data modalities. Deep hash networks have shown high potential in achieving efficient and effective cross-media search performance. However, due to the fact that social network data often exhibit text sparsity, diversity, and noise characteristics, the search performance of existing methods often degrades when dealing with this data. In order to address this problem, this article proposes a novel end-to-end cross-media semantic correlation learning model based on a deep hash network and semantic expansion for social network cross-media search (DHNS). The approach combines deep network feature learning and hash-code quantization learning for multimodal data into a unified optimization architecture, which successfully preserves both intramedia similarity and intermedia correlation, by minimizing both cross-media correlation loss and binary hash quantization loss. In addition, our approach realizes semantic relationship expansion by constructing the image-word relation graph and mining the potential semantic relationship between images and words, and obtaining the semantic embedding based on both internal graph deep walk and an external knowledge base. Experimental results demonstrate that DHNS yields better cross-media search performance on standard benchmarks."}, "journals/www/ZhouDYCXL20": {"title": "A content search method for security topics in microblog based on deep reinforcement learning.", "url": "https://doi.org/10.1007/s11280-019-00697-7", "year": "2020", "author": {"Nan Zhou": "06/5140", "Junping Du": "13/1151", "Xu Yao": "118/3673", "Wanqiu Cui": "223/2328", "Zhe Xue": "116/7294", "MeiYu Liang": "150/1513"}, "abstract": "Traditional methods treat the search problem as a process of selecting and ranking sequential documents. The methods have been proved effective and are widely used in the web search domain. However, due to the complexity and particularity of microblog text contents, the classical methods are rarely used microblog searches for specific topics. Focusing on the issue of searching for specific topics in microblog content, we present a microblog search method for security topics based on deep reinforcement learning by modeling the microblog search for specific topics as a continuous-state Markov decision process. We also design a novel deep Q network to evaluate the relevance of microblog content based on the target topic. We adopt reinforcement learning to solve the microblog search problem using an intelligent strategy and evaluate content relevance through deep learning. Experiments conducted on a real-world dataset show that our approach outperforms the selected baseline methods."}, "journals/ijcat/DingZZLL19": {"title": "Improved face recognition with accelerated robust features improved by means of mean shift k-means clustering.", "url": "https://doi.org/10.1504/IJCAT.2019.102089", "year": "2019", "author": {"Jiao Ding": "99/1225", "Minfeng Zhang": "249/8705", "Tianfei Zhang": "116/8442", "Haiyan Long": "92/4884", "MeiYu Liang": "150/1513"}, "abstract": ""}, "journals/ijon/KouDYSLXL19": {"title": "A multi-feature probabilistic graphical model for social network semantic search.", "url": "https://doi.org/10.1016/j.neucom.2018.03.086", "year": "2019", "author": {"Feifei Kou": "223/2313", "Junping Du": "13/1151", "Cong-Xian Yang": "223/2400", "Yan-Song Shi": "223/2263", "MeiYu Liang": "150/1513", "Zhe Xue": "116/7294", "Haisheng Li 0002": "145/2836-2"}, "abstract": "With the rapid development of social network platforms, more and more people are using them to search for material related to their interests. As the texts of social media messages are usually so short, when traditional existing document modeling methods are used in social network search tasks, the problem of semantic sparsity arises, leading to low-quality semantic representation and low-precision social network search results. Fortunately, besides of short text, social media data also has other features, such as timestamps, locations, and its user information. In light of this, to realize precise social network search, we propose a multi-feature probabilistic graphical model (MFPGM), which can generate high-quality semantic representation. To deal with the problem of semantic sparsity, we exploit two strategies in MFPGM. First, we propose a concept named special region and utilize location information to aggregate short text into long text. Second, we introduce the biterm pattern that can generate dense semantic space by supposing that a biterm occurring in the same context has the same topic. In order to generate high-quality semantic representations, we simultaneously model multiple features (i.e., biterm, user, location and timestamp) of social network data to enhance the semantic learning process of MFPGM. We conduct a lot of experiments on real-word datasets, and the comparisons with several state-of-art baseline methods have demonstrated the superiority of our MFPGM on topic quality and search performance. Additionally, with the help of the generated semantic representations, MFPGM allows people to analyze the relationships between time and the popularities of topics."}, "journals/jise/ShiDLK19": {"title": "SRTM: A Sparse RNN-Topic Model for Discovering Bursty Topics in Big Data of Social Networks.", "url": "https://jise.iis.sinica.edu.tw/JISESearch/pages/View/PaperView.jsf?keyId=169_2248", "year": "2019", "author": {"Lei Shi": "29/563", "Junping Du": "13/1151", "MeiYu Liang": "150/1513", "Fei-Fei Kou": "223/2313"}, "abstract": ""}, "journals/ppna/ShiDLK19": {"title": "Dynamic topic modeling via self-aggregation for short text streams.", "url": "https://doi.org/10.1007/s12083-018-0692-7", "year": "2019", "author": {"Lei Shi": "29/563", "Junping Du": "13/1151", "MeiYu Liang": "150/1513", "Feifei Kou": "223/2313"}, "abstract": "Social networks such as Twitter, Facebook, and Sina microblogs have emerged as major sources for discovering and sharing the latest topics. Because social network topics change quickly, developing an effective method to model such topics is urgently needed. However, topic modeling is challenging due to the sparsity problem and the dynamic change of topics in microblog streams. In this study, we propose dynamic topic modeling via a self-aggregation method (SADTM) that can capture the time-varying aspect of topic distributions and resolve the sparsity problem. The SADTM aggregates the observable and unordered short texts as the aggregated document without leveraging an external context to overcome the sparsity problem of short text. Furthermore, we exploit word pairs instead of words for each microblog to generate more word co-occurrence patterns. The SADTM models temporal dynamics by using the topic distribution at previous time steps in microblog streams to infer the current topic from sequential data. Extensive experiments on a real-world Sina microblog dataset demonstrate that our SADTM algorithm outperforms several state-of-the-art methods in topic coherence and cluster quality. Additionally, when applied in a search scene, our SADTM significantly outperforms all baseline methods in terms of the quality of the search results."}, "journals/prl/WeiDLY19": {"title": "Boosting deep attribute learning via support vector regression for fast moving crowd counting.", "url": "https://doi.org/10.1016/j.patrec.2017.12.002", "year": "2019", "author": {"Xinlei Wei": "195/7472", "Junping Du": "13/1151", "MeiYu Liang": "150/1513", "Lingfei Ye": "192/0991"}, "abstract": "Crowd counting has recently attracted extensive attention in research. However, the existing research mainly focuses on investigating crowd counting of static or slow moving crowd estimating, while fast moving crowd counting is left unexplored. The fast moving crowd counting is indeed extremely important for urban public safety management. In this paper, we propose a novel more effective fast moving crowd counting algorithm. The proposed approach utilizes support vector regression and spatial-temporal multi-features to boost deep cumulative attribute learning. To this end, first a novel spatial-temporal multi-feature is proposed by joining super-pixel based multi-appearance features and multi-motion features to solve fast moving crowd counting. Second, a novel deep accumulated attributes learning architecture is proposed based on very deep learning architecture VGG16. Third, a novel boosting deep attribute Learning algorithm is proposed based on late fusion of proposed deep cumulative attribute learning and proposed spatial-temporal multi-features based support vector regression for improving predication performance of deep learning. We perform corresponding experiments on three public datasets including UCSD dataset, PEST2009 dataset and Mall dataset. The experimental results demonstrate that proposed Boosting DAL-SVR method is effective to cover the shortage of deep learning in solving regression problems. Meanwhile it demonstrates that proposed Boosting DAL-SVR is more effective and robust rather than other state-of-the art methods for fast moving crowd counting problem."}, "journals/www/GengDL19": {"title": "Abnormal event detection in tourism video based on salient spatio-temporal features and sparse combination learning.", "url": "https://doi.org/10.1007/s11280-018-0603-0", "year": "2019", "author": {"Yue Geng": "23/5510", "Junping Du": "13/1151", "MeiYu Liang": "150/1513"}, "abstract": "With the booming development of tourism, travel security problems are becoming more and more prominent. Congestion, stampedes, fights and other tourism emergency events occurred frequently, which should be a wake-up call for tourism security. Therefore, it is of great research value and application prospect to real-time monitor tourists and detect abnormal events in tourism surveillance video by using computer vision and video intelligent processing technology, which can realize the timely forecast and early warning of tourism emergencies. At present, although most of the video-based abnormal event detection methods work well in simple scenes, there are often problems such as low detection rate and high false positive rate in complex motion scenarios, and the detection of abnormal events can’t be processed in real time. To tackle these issues, we propose an abnormal event detection model in tourism video based on salient spatio-temporal features and sparse combination learning, which has good robustness and timeliness in complex motion scenarios and can be adapted to real-time anomaly detection in practical applications. Specifically, spatio-temporal gradient model is combined with foreground detection to extract 3D gradient features on the foreground target of video sequence as the salient spatio-temporal features, which can eliminate the interference of the background. Sparse combination learning algorithm is used to establish the abnormal event detection model, which can realize the real-time detection of abnormal events. In addition, we construct a new ScenicSpot dataset with 18 video clips (5964 frames) containing both normal and abnormal events. The experimental results on ScenicSpot dataset and two standard benchmark datasets show that our method can realize the automatic detection and recognition of tourists’ abnormal behavior, and has better performance compared with the classical methods."}, "journals/www/CuiDWKLXZ19": {"title": "Extended search method based on a semantic hashtag graph combining social and conceptual information.", "url": "https://doi.org/10.1007/s11280-018-0584-z", "year": "2019", "author": {"Wanqiu Cui": "223/2328", "Junping Du": "13/1151", "Dawei Wang": "39/2537", "Feifei Kou": "223/2313", "MeiYu Liang": "150/1513", "Zhe Xue": "116/7294", "Nan Zhou": "06/5140"}, "abstract": "Searching for microblog short text by their meaning is a challenging task because of the semantic sparsity of the information in social networks. The extended search approaches are commonly accepted which facilitate short text understanding and search by enriching the short text. However, they only analyze the literal semantics of short text, and the unique social characteristics of social network which also contain semantic information are not utilized well. To better capture the rich semantics in microblog short text, we propose a new microblog short text extended search method based on a semantic hashtag graph by combining social and conceptual information, which enriches each short text by concepts and associated hashtags to represent whole semantic features. Considering the microblog context, we introduce concepts through Wikipedia, as well as semantic consistency of hashtags. Specifically, for conceptual semantics, we propose a conceptual analysis method which merges explicit and implicit information in Wikipedia. For social semantics in hashtags, a semantic hashtag graph which combines social and conceptual information is put forward to generate semantic associated hashtags. We conduct experiments and the results show that our method is obviously better than the other existing state-of-the-art approaches in semantic understanding and search of short text."}, "journals/jcst/KouDYSCLG18": {"title": "Hashtag Recommendation Based on Multi-Features of Microblogs.", "url": "https://doi.org/10.1007/s11390-018-1851-2", "year": "2018", "author": {"Fei-Fei Kou": "223/2313", "Junping Du": "13/1151", "Cong-Xian Yang": "223/2400", "Yan-Song Shi": "223/2263", "Wan-Qiu Cui": "223/2328", "MeiYu Liang": "150/1513", "Yue Geng": "23/5510"}, "abstract": "Hashtag recommendation for microblogs is a very hot research topic that is useful to many applications involving microblogs. However, since short text in microblogs and low utilization rate of hashtags will lead to the data sparsity problem, it is difficult for typical hashtag recommendation methods to achieve accurate recommendation. In light of this, we propose HRMF, a hashtag recommendation method based on multi-features of microblogs in this article. First, our HRMF expands short text into long text, and then it simultaneously models multi-features (i.e., user, hashtag, text) of microblogs by designing a new topic model. To further alleviate the data sparsity problem, HRMF exploits hashtags of both similar users and similar microblogs as the candidate hashtags. In particular, to find similar users, HRMF combines the designed topic model with typical user-based collaborative filtering method. Finally, we realize hashtag recommendation by calculating the recommended score of each hashtag based on the generated topical representations of multi-features. Experimental results on a real-world dataset crawled from Sina Weibo demonstrate the effectiveness of our HRMF for hashtag recommendation."}, "journals/jocs/KouDLLLSY18": {"title": "A semantic modeling method for social network short text based on spatial and temporal characteristics.", "url": "https://doi.org/10.1016/j.jocs.2017.10.012", "year": "2018", "author": {"Feifei Kou": "223/2313", "Junping Du": "13/1151", "Zijian Lin": "207/4667", "MeiYu Liang": "150/1513", "Haisheng Li 0002": "145/2836-2", "Lei Shi": "29/563", "Cong-Xian Yang": "223/2400"}, "abstract": "Given the social network short text native sparsity, semantic inference becomes an infeasible task for conventional topic models. By exploiting the spatial and temporal characteristics of social network data, we propose a social network short text semantic modeling method, named by Spatial and Temporal Topic Model (STTM). To further overcome short text sparsity, STTM leverages co-occurrence word–word pair to reduce the sparsity problem, and moreover, it incorporates time information into the process of topics modeling in order to generate topics with higher quality. Experimental results over four real social media datasets verify the effectiveness of STTM."}, "journals/mta/LiangDL16": {"title": "Video super-resolution reconstruction based on correlation learning and spatio-temporal nonlocal similarity.", "url": "https://doi.org/10.1007/s11042-015-2952-3", "year": "2016", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Linghui Li": "19/10136"}, "abstract": "A novel video super-resolution reconstruction algorithm based on correlation learning and spatio-temporal nonlocal similarity is proposed in this paper. Objective high-resolution (HR) estimates of low-resolution (LR) video frames can be obtained by learning LR-HR correlation mapping and fusing the spatio-temporal nonlocal similarity information between video frames. First, the LR-HR correlation mapping between LR and HR patches is established based on semi-coupled dictionary learning. With the aim of improving algorithm efficiency while guaranteeing super-resolution quality, LR-HR correlation mapping is performed only for the salient object region, and then an improved visual saliency-based nonlocal fuzzy registration scheme using the pseudo-Zernike moment feature and structural similarity is proposed for spatio-temporal similarity matching and fusion. Visual saliency and self-adaptive regional correlation evaluation strategies are used in spatio-temporal similarity matching to improve algorithm efficiency further. Experimental results demonstrate that the proposed algorithm achieves competitive super-resolution quality compared to other state-of-the-art algorithms in terms of both subjective and objective evaluations."}, "journals/iet-ipr/LiangDCL15": {"title": "Super-resolution reconstruction based on multisource bidirectional similarity and non-local similarity matching.", "url": "https://doi.org/10.1049/iet-ipr.2014.0658", "year": "2015", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Shouxin Cao": "08/10150", "Linghui Li": "19/10136"}, "abstract": ""}, "journals/chinaf/LiangDL14": {"title": "Self-adaptive spatial image denoising model based on scale correlation and SURE-LET in the nonsubsampled contourlet transform domain.", "url": "https://doi.org/10.1007/s11432-013-4943-1", "year": "2014", "author": {"MeiYu Liang": "150/1513", "Junping Du": "13/1151", "Honggang Liu": "26/2948"}, "abstract": "A novel self-adaptive image denoising model based on scale correlation and Stein’s unbiased risk estimate-linear expansion of thresholds (SURE-LET) in the nonsubsampled contourlet transform domain is proposed in this paper. First we implement the multidimensional and translation invariant decomposition for spatial images by the nonsubsampled contourlet transform, and establish the image cross-scale description structure. Then combining the scale correlation, we make improvements for the existing SURE-LET denoising idea and establish the self-adaptive denoising mechanism. The scale correlation calculation is needed for the coefficients at different scales and sub-bands to determine whether the coefficients are retained or processed with the adaptive SURE-LET threshold shrinkage. And meanwhile a new local context self-adaptive threshold strategy is proposed in the process of scale correlation calculation. Experimental results both on spatial images and standard images demonstrate that the proposed algorithm performs significantly better in terms of both the visual subjective evaluation and the quantitative objective evaluation. The method can achieve better noise suppression, and effectively retain image edge details."}}}